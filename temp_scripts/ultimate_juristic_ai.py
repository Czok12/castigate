"""
ðŸŒŸ ULTIMATE JURISTISCHE WISSENSDATENBANK
=======================================

Master-Integration aller Ultra-Advanced Module fÃ¼r die ultimative juristische KI-Anwendung
"""

import time
from typing import Any, Dict, List, Optional

import plotly.graph_objects as go
import streamlit as st

# Import aller Ultra-Advanced Module
try:
    from advanced_retrieval_engine import MultiStageRetriever
except ImportError:
    MultiStageRetriever = None
try:
    from answer_quality_system import ConfidenceCalculator, StructuredAnswerGenerator
except ImportError:
    ConfidenceCalculator = None
    StructuredAnswerGenerator = None
try:
    from auto_optimizing_system import AutoOptimizingSystemManager
except ImportError:
    AutoOptimizingSystemManager = None
try:
    from explainable_ai_dashboard import ExplainableAIEngine
except ImportError:
    ExplainableAIEngine = None
try:
    from intelligent_caching_system import HierarchicalCacheManager
except ImportError:
    HierarchicalCacheManager = None
try:
    from multi_agent_legal_system import MultiAgentCoordinator
except ImportError:
    MultiAgentCoordinator = None
try:
    from neural_retrieval_fusion import (
        NeuralRetrievalFusion,
        simulate_retrieval_candidates,
    )
except ImportError:
    NeuralRetrievalFusion = None
    simulate_retrieval_candidates = None
try:
    from performance_monitoring import AutoOptimizer, PerformanceMonitor
except ImportError:
    AutoOptimizer = None
    PerformanceMonitor = None
try:
    from predictive_query_completion import PredictiveQueryEngine, UserContext
except ImportError:
    PredictiveQueryEngine = None
    UserContext = None
try:
    from quantum_inspired_optimizer import QuantumInspiredOptimizer
except ImportError:
    QuantumInspiredOptimizer = None
try:
    from realtime_adaptive_learning import InteractionEvent, RealTimeLearningEngine
except ImportError:
    InteractionEvent = None
    RealTimeLearningEngine = None
try:
    from semantic_query_enhancer import SemanticQueryEnhancer
except ImportError:
    SemanticQueryEnhancer = None

print("âœ… Alle Ultra-Advanced Module erfolgreich geladen")

# Streamlit Konfiguration
st.set_page_config(
    page_title="ðŸŒŸ Ultimate Juristische Wissensdatenbank",
    page_icon="ðŸŒŸ",
    layout="wide",
    initial_sidebar_state="expanded",
)


class UltimateJuristicAI:
    """Master-Klasse fÃ¼r ultimative juristische KI-Anwendung"""

    def __init__(self):
        self.neural_fusion = None
        self.predictive_engine = None
        self.auto_optimizer = None
        self.adaptive_learning = None
        self.cache_manager = None
        self.query_enhancer = None
        # Neue Ultra-Module
        self.quantum_optimizer = None
        self.multi_agent_coordinator = None
        self.explainable_ai_engine = None

        # System-Status
        self.system_initialized = False
        self.performance_metrics = {}
        self.session_stats = {
            "queries_processed": 0,
            "avg_response_time": 0.0,
            "accuracy_score": 0.0,
            "user_satisfaction": 0.0,
        }

        # Initialize wenn Module verfÃ¼gbar
        self._initialize_all_modules()

    def _initialize_all_modules(self):
        """Initialisiert alle Ultra-Advanced Module inkl. Quantum, Multi-Agent, Explainable AI"""
        try:
            # Neural Retrieval Fusion
            if NeuralRetrievalFusion is not None:
                self.neural_fusion = NeuralRetrievalFusion()
            # Predictive Query Completion
            if PredictiveQueryEngine is not None:
                self.predictive_engine = PredictiveQueryEngine()
            # Auto-Optimizing System
            if AutoOptimizingSystemManager is not None:
                self.auto_optimizer = AutoOptimizingSystemManager()
            # Real-Time Adaptive Learning
            if RealTimeLearningEngine is not None:
                self.adaptive_learning = RealTimeLearningEngine()
            # Cache Manager
            if HierarchicalCacheManager is not None:
                self.cache_manager = HierarchicalCacheManager()
            # Query Enhancer
            if SemanticQueryEnhancer is not None:
                self.query_enhancer = SemanticQueryEnhancer()
            # Neue Ultra-Module initialisieren
            if QuantumInspiredOptimizer is not None:
                self.quantum_optimizer = QuantumInspiredOptimizer(
                    {
                        "retrieval_top_k": (5, 50),
                        "similarity_threshold": (0.1, 0.9),
                        "chunk_size": (100, 2000),
                        "overlap_size": (10, 200),
                        "temperature": (0.1, 1.0),
                        "top_p": (0.1, 1.0),
                        "cache_ttl": (60, 3600),
                        "neural_fusion_weight": (0.0, 1.0),
                    }
                )
            if MultiAgentCoordinator is not None:
                self.multi_agent_coordinator = MultiAgentCoordinator()
            if ExplainableAIEngine is not None:
                self.explainable_ai_engine = ExplainableAIEngine()

            self.system_initialized = True
            print("ðŸš€ Ultimate Juristische AI vollstÃ¤ndig initialisiert")

        except ImportError as e:
            st.error(f"âŒ Fehler beim Laden der Module: {e}")
            MODULES_AVAILABLE = False
        except Exception as e:
            st.error(f"âŒ Fehler bei Module-Initialisierung: {e}")
            self.system_initialized = False

    def process_ultimate_query(
        self, query: str, user_context: Optional[UserContext] = None
    ) -> Dict[str, Any]:
        """Prozessiert Query mit allen Ultra-Advanced Features"""

        if not self.system_initialized:
            return {"error": "System nicht initialisiert"}

        start_time = time.time()

        # 1. Predictive Completion (falls Query unvollstÃ¤ndig)
        if (
            self.predictive_engine
            and hasattr(self.predictive_engine, "predict_completions")
            and len(query.strip()) < 10
        ):
            completions = self.predictive_engine.predict_completions(
                partial_query=query, user_context=user_context, max_predictions=5
            )
            return {
                "type": "completions",
                "suggestions": completions,
                "processing_time": time.time() - start_time,
            }

        # 2. Query Enhancement
        enhanced_query = query
        if self.query_enhancer and hasattr(self.query_enhancer, "enhance_query"):
            enhanced_query = self.query_enhancer.enhance_query(query)
            if not isinstance(enhanced_query, str):
                enhanced_query = getattr(enhanced_query, "text", str(enhanced_query))

        # 3. Cache Check
        cache_result = None
        if self.cache_manager and hasattr(self.cache_manager, "get_cached_answer"):
            cache_result = self.cache_manager.get_cached_answer(enhanced_query)
        if cache_result:
            return {
                "type": "cached_response",
                "answer": cache_result["answer"],
                "confidence": cache_result.get("confidence_score", 0.0),
                "source": cache_result.get("retrieval_method", "intelligent_cache"),
                "processing_time": time.time() - start_time,
                "cache_hit": True,
            }

        # 4. Retrieval Candidates generieren (simuliert)
        candidates = []
        try:
            if self.neural_fusion and "simulate_retrieval_candidates" in globals():
                candidates = simulate_retrieval_candidates(enhanced_query, count=10)
        except Exception:
            candidates = []
        # 5. Neural Fusion fÃ¼r optimales Ranking
        fusion_results = []
        try:
            if self.neural_fusion and hasattr(
                self.neural_fusion, "fuse_retrieval_results"
            ):
                fusion_results = self.neural_fusion.fuse_retrieval_results(
                    candidates=candidates,
                    query=enhanced_query,
                    strategy="adaptive_ranking",
                    top_k=5,
                )
        except Exception:
            fusion_results = []
        # 6. Answer Generation (vereinfacht)
        answer = (
            self._generate_ultimate_answer(fusion_results, enhanced_query)
            if hasattr(self, "_generate_ultimate_answer")
            else {
                "content": "Keine Antwort generiert",
                "confidence": 0.0,
                "metadata": {},
            }
        )
        # 7. Cache speichern
        if (
            self.cache_manager
            and hasattr(self.cache_manager, "cache_answer")
            and answer
        ):
            self.cache_manager.cache_answer(
                query=enhanced_query,
                answer=answer.get("content", ""),
                sources=[],
                confidence_score=answer.get("confidence", 0.0),
                retrieval_method="neural_fusion",
                performance_metrics={"response_time": time.time() - start_time},
            )

        # 8. Adaptive Learning Update
        # Adaptive Learning Update robust prÃ¼fen
        if (
            InteractionEvent is not None
            and self.adaptive_learning
            and hasattr(self.adaptive_learning, "process_interaction")
        ):
            try:
                interaction = InteractionEvent(
                    timestamp=time.time(),
                    query=query,
                    enhanced_query=enhanced_query,
                    intent=(
                        enhanced_query.split()[0]
                        if isinstance(enhanced_query, str) and enhanced_query
                        else "unknown"
                    ),
                    response_time=time.time() - start_time,
                    confidence_score=answer.get("confidence", 0.0),
                    retrieval_method="neural_fusion",
                    sources_count=len(fusion_results),
                    session_id=user_context.session_id if user_context else "default",
                )
                self.adaptive_learning.process_interaction(interaction)
            except Exception as e:
                st.warning(f"Adaptive Learning konnte nicht ausgefÃ¼hrt werden: {e}")

        # 9. Session-Stats aktualisieren
        self._update_session_stats(time.time() - start_time, answer["confidence"])

        processing_time = time.time() - start_time

        return {
            "type": "ultimate_answer",
            "answer": answer,
            "fusion_results": [
                (candidate.content[:100] + "...", result.final_score)
                for candidate, result in fusion_results[:3]
            ],
            "enhanced_query": enhanced_query,
            "processing_time": processing_time,
            "cache_hit": False,
            "neural_fusion_used": True,
            "adaptive_learning_applied": True,
        }

    def _generate_ultimate_answer(
        self, fusion_results: List, query: str
    ) -> Dict[str, Any]:
        """Generiert ultimative Antwort aus Fusion-Ergebnissen"""

        if not fusion_results:
            return {
                "content": "Keine relevanten Ergebnisse gefunden.",
                "confidence": 0.1,
                "metadata": {"sources": 0},
            }

        # Top-Result als Basis
        top_candidate, top_fusion = fusion_results[0]

        # Ultimate Answer zusammenstellen
        answer_content = f"""
## ðŸ“‹ Juristische Analyse: {query}

### ðŸŽ¯ Hauptantwort
{top_candidate.content}

### ðŸ“Š ZusÃ¤tzliche Erkenntnisse
Basierend auf {len(fusion_results)} relevanten Quellen mit Neural Fusion Ranking:

"""

        # Top-3 Quellen hinzufÃ¼gen
        for i, (candidate, fusion_result) in enumerate(fusion_results[:3], 1):
            answer_content += f"""
**{i}. Quelle (Relevanz: {fusion_result.final_score:.3f})**
{candidate.content[:200]}...
*Retrievalmethode: {candidate.retrieval_method}*

"""

        # Confidence aus Fusion-Results berechnen
        avg_confidence = sum(result.confidence for _, result in fusion_results) / len(
            fusion_results
        )

        return {
            "content": answer_content,
            "confidence": avg_confidence,
            "metadata": {
                "sources": len(fusion_results),
                "neural_fusion_strategy": "adaptive_ranking",
                "top_score": fusion_results[0][1].final_score,
                "query_enhanced": True,
            },
        }

    def _update_session_stats(self, response_time: float, confidence: float):
        """Aktualisiert Session-Statistiken"""

        self.session_stats["queries_processed"] += 1

        # Rolling Average fÃ¼r Response-Zeit
        current_avg = self.session_stats["avg_response_time"]
        count = self.session_stats["queries_processed"]
        self.session_stats["avg_response_time"] = (
            current_avg * (count - 1) + response_time
        ) / count

        # Rolling Average fÃ¼r Accuracy
        current_acc = self.session_stats["accuracy_score"]
        self.session_stats["accuracy_score"] = (
            current_acc * (count - 1) + confidence
        ) / count

    def get_system_analytics(self) -> Dict[str, Any]:
        """Gibt umfassende System-Analytics zurÃ¼ck"""

        analytics = {
            "session_stats": self.session_stats,
            "system_status": {
                "initialized": self.system_initialized,
                "modules_loaded": True,
                "uptime": "Aktiv",
            },
        }

        if self.system_initialized:
            # Neural Fusion Analytics
            if self.neural_fusion:
                analytics["neural_fusion"] = self.neural_fusion.get_fusion_analytics()

            # Predictive Engine Analytics
            if self.predictive_engine:
                analytics["predictive_completion"] = (
                    self.predictive_engine.get_completion_analytics()
                )

            # Auto-Optimizer Status
            if self.auto_optimizer:
                analytics["auto_optimization"] = self.auto_optimizer.get_system_status()

            # Cache Analytics
            if self.cache_manager:
                analytics["cache_performance"] = (
                    self.cache_manager.get_cache_analytics()
                )

        return analytics

    def start_auto_optimization(self):
        """Startet automatische System-Optimierung"""
        if self.auto_optimizer and self.system_initialized:
            self.auto_optimizer.start_auto_optimization()
            return True
        return False

    def stop_auto_optimization(self):
        """Stoppt automatische System-Optimierung"""
        if self.auto_optimizer:
            self.auto_optimizer.stop_auto_optimization()
            return True
        return False

    def run_quantum_optimization(self, max_iterations=50):
        """Starte Quantum-Optimierung und gebe Report zurÃ¼ck"""
        if not self.quantum_optimizer:
            return {"error": "Quantum-Optimizer nicht initialisiert"}

        # Dummy-Objektivfunktion (kann spÃ¤ter angepasst werden)
        def mock_rag_performance(params):
            score = 0.0
            score += 0.3 * (1.0 - abs(params["retrieval_top_k"] - 20) / 45)
            score += 0.2 * (1.0 - abs(params["similarity_threshold"] - 0.7) / 0.8)
            score += 0.2 * (1.0 - abs(params["chunk_size"] - 800) / 1900)
            score += 0.1 * (1.0 - abs(params["overlap_size"] - 50) / 190)
            score += 0.1 * (1.0 - abs(params["temperature"] - 0.3) / 0.9)
            score += 0.1 * (1.0 - abs(params["top_p"] - 0.9) / 0.9)
            score += 0.05 * (1.0 - abs(params["cache_ttl"] - 600) / 3540)
            score += 0.05 * (1.0 - abs(params["neural_fusion_weight"] - 0.7) / 1.0)
            return max(0.0, min(1.0, score))

        result = self.quantum_optimizer.quantum_annealing_optimization(
            objective_function=mock_rag_performance, max_iterations=max_iterations
        )
        report = self.quantum_optimizer.get_quantum_performance_report()
        return {"result": result, "report": report}

    async def run_multi_agent_analysis(self, legal_query):
        """Starte Multi-Agenten-Analyse fÃ¼r eine juristische Anfrage"""
        if not self.multi_agent_coordinator:
            return {"error": "Multi-Agent-System nicht initialisiert"}
        return await self.multi_agent_coordinator.process_collaborative_query(
            legal_query
        )

    def start_explainable_trace(self, query, components):
        """Starte Explainable-AI-Trace fÃ¼r eine Anfrage"""
        if not self.explainable_ai_engine:
            return None
        return self.explainable_ai_engine.trace_decision_process(query, components)

    def get_explainable_dashboard(self, trace_id):
        """Hole interaktives Explainable-AI-Dashboard fÃ¼r Trace"""
        if not self.explainable_ai_engine:
            return None
        return self.explainable_ai_engine.create_interactive_explanation_dashboard(
            trace_id
        )


# Streamlit UI
def main():
    """Hauptfunktion fÃ¼r Streamlit App"""

    st.title("ðŸŒŸ Ultimate Juristische Wissensdatenbank")
    st.markdown("*Powered by Neural Fusion, Predictive Completion & Auto-Optimization*")

    # Initialize Ultimate AI
    if "ultimate_ai" not in st.session_state:
        st.session_state.ultimate_ai = UltimateJuristicAI()

    ultimate_ai = st.session_state.ultimate_ai

    # Sidebar fÃ¼r System-Kontrolle
    with st.sidebar:
        st.header("ðŸŽ›ï¸ System-Kontrolle")

        if st.button("ðŸš€ Auto-Optimization starten"):
            if ultimate_ai.start_auto_optimization():
                st.success("âœ… Auto-Optimization gestartet")
            else:
                st.error("âŒ Fehler beim Starten")

        if st.button("ðŸ›‘ Auto-Optimization stoppen"):
            if ultimate_ai.stop_auto_optimization():
                st.success("âœ… Auto-Optimization gestoppt")

        st.markdown("---")

        # Quantum-Optimierung
        st.subheader("ðŸŒŒ Quantum-Optimierung")
        if st.button("Quantum-Optimierung ausfÃ¼hren"):
            with st.spinner("Quantum-Optimizer lÃ¤uft..."):
                quantum_result = ultimate_ai.run_quantum_optimization()
                # Quantum-Optimierung Ergebnis robust behandeln
                if isinstance(quantum_result, dict):
                    st.success("Quantum-Optimierung abgeschlossen!")
                    st.write("**Optimale Parameter:**")
                    st.json(quantum_result.get("result", {}))
                    st.write("**Quantum-Performance-Report:**")
                    st.json(quantum_result.get("report", {}))
                else:
                    st.write(str(quantum_result))

        # Multi-Agenten-Analyse (Demo-Button)
        st.markdown("---")
        st.subheader("ðŸ¤– Multi-Agenten-Analyse (Demo)")
        if st.button("Multi-Agenten-Analyse ausfÃ¼hren"):
            import asyncio

            from multi_agent_legal_system import LegalDomain, LegalQuery

            with st.spinner("Multi-Agenten-System arbeitet..."):
                # Beispiel-Query
                legal_query = LegalQuery(
                    query_id="demo1",
                    original_question="Welche Voraussetzungen hat die Anfechtung eines Vertrags?",
                    processed_question="Voraussetzungen Anfechtung Vertrag",
                    legal_domain=LegalDomain.CIVIL_LAW,
                    complexity_score=0.5,
                    urgency_level=2,
                    required_accuracy=0.8,
                    context_information={},
                )
                try:
                    result = asyncio.run(
                        ultimate_ai.run_multi_agent_analysis(legal_query)
                    )
                    # Multi-Agenten-Analyse Ergebnis robust behandeln
                    if isinstance(result, dict):
                        st.write("**Kollaborative Antwort:**")
                        st.write(result.get("final_answer", "Keine Antwort"))
                        st.write(
                            "**Consensus-Score:**", result.get("consensus_score", "-")
                        )
                        st.write(
                            "**Beteiligte Agenten:**",
                            result.get("contributing_agents", []),
                        )
                    else:
                        st.write(str(result))
                    st.success("Multi-Agenten-Analyse abgeschlossen!")
                except Exception as e:
                    st.error(f"Fehler bei Multi-Agenten-Analyse: {e}")

        st.markdown("---")
        # Explainable AI Dashboard (Trace-Auswahl)
        st.subheader("ðŸ” Explainable AI Dashboard")
        trace_id = st.text_input("Trace-ID fÃ¼r Dashboard:")
        if st.button("Dashboard anzeigen") and trace_id:
            dashboard_fig = ultimate_ai.get_explainable_dashboard(trace_id)
            if dashboard_fig:
                st.plotly_chart(dashboard_fig, use_container_width=True)
            else:
                st.warning("Kein Dashboard fÃ¼r diese Trace-ID gefunden.")

        st.markdown("---")

        # System-Status
        st.subheader("ðŸ“Š System-Status")
        if ultimate_ai.system_initialized:
            st.success("ðŸŸ¢ System initialisiert")
        else:
            st.error("ðŸ”´ System nicht bereit")

        # Session-Stats
        stats = ultimate_ai.session_stats
        st.metric("Queries verarbeitet", stats["queries_processed"])
        st.metric("â±ï¸ Ã˜ Response-Zeit", f"{stats['avg_response_time']:.3f}s")
        st.metric("ðŸŽ¯ Ã˜ Accuracy", f"{stats['accuracy_score']:.2%}")

    # Hauptbereich
    col1, col2 = st.columns([2, 1])

    with col1:
        st.header("ðŸ” Juristische Anfrage")

        # User Context Setup
        # Fallback fÃ¼r UserContext-Erstellung
        user_context = None
        if UserContext is not None:
            try:
                user_context = UserContext(
                    session_id=st.session_state.get("session_id", "streamlit_session"),
                    query_history=st.session_state.get("query_history", []),
                    topic_preferences={"vertragsrecht": 0.8, "strafrecht": 0.6},
                    complexity_preference=0.7,
                    search_patterns={},
                    time_of_day="afternoon",
                    recent_documents=[],
                    expertise_level=0.6,
                )
            except Exception as e:
                st.warning(f"UserContext konnte nicht erzeugt werden: {e}")

        # Query Input
        query = st.text_area(
            "Ihre juristische Frage:",
            placeholder="z.B. Voraussetzungen eines Kaufvertrags nach BGB...",
            height=100,
        )

        # Query Processing
        if st.button("ðŸ” Anfrage verarbeiten", type="primary"):
            if query.strip():
                with st.spinner("ðŸ§  Neural Fusion + Predictive AI arbeitet..."):
                    result = ultimate_ai.process_ultimate_query(query, user_context)

                # Query History aktualisieren
                if "query_history" not in st.session_state:
                    st.session_state.query_history = []
                st.session_state.query_history.append(query)

                # Ergebnis anzeigen
                if result["type"] == "completions":
                    st.subheader("ðŸ”® Query-VervollstÃ¤ndigung")
                    st.info(
                        "Ihre Anfrage scheint unvollstÃ¤ndig. Hier sind intelligente VorschlÃ¤ge:"
                    )

                    for i, completion in enumerate(result["suggestions"], 1):
                        st.write(f"{i}. **{completion.completion}**")
                        st.write(
                            f"   Confidence: {completion.confidence:.2%} | Type: {completion.prediction_type}"
                        )

                elif result["type"] in ["ultimate_answer", "cached_response"]:
                    st.subheader("ðŸ“‹ Juristische Antwort")

                    # Performance-Badges
                    col_a, col_b, col_c = st.columns(3)
                    with col_a:
                        st.metric(
                            "â±ï¸ Response-Zeit", f"{result['processing_time']:.3f}s"
                        )
                    with col_b:
                        cache_status = (
                            "ðŸŽ¯ Cache Hit"
                            if result.get("cache_hit")
                            else "ðŸ§  Neural Fusion"
                        )
                        st.metric("Verarbeitung", cache_status)
                    with col_c:
                        conf = (
                            result["answer"]["confidence"]
                            if "answer" in result
                            else result.get("confidence", 0)
                        )
                        st.metric("ðŸŽ¯ Confidence", f"{conf:.1%}")

                    # Antwort anzeigen
                    answer_content = (
                        result["answer"]["content"]
                        if "answer" in result
                        else result.get("answer", "")
                    )
                    st.markdown(answer_content)

                    # Fusion-Results (falls verfÃ¼gbar)
                    if "fusion_results" in result:
                        with st.expander("ðŸ§  Neural Fusion Details"):
                            st.subheader("Top-3 Fusion-Ergebnisse:")
                            for i, (content, score) in enumerate(
                                result["fusion_results"], 1
                            ):
                                st.write(f"**{i}. (Score: {score:.3f})**")
                                st.write(content)
                                st.markdown("---")
            else:
                st.warning("âš ï¸ Bitte geben Sie eine Frage ein")

    with col2:
        st.header("ðŸ“ˆ Live-Analytics")

        # System-Analytics abrufen
        analytics = ultimate_ai.get_system_analytics()

        # Performance-Chart
        if analytics["session_stats"]["queries_processed"] > 0:
            fig = go.Figure()
            fig.add_trace(
                go.Indicator(
                    mode="gauge+number",
                    value=analytics["session_stats"]["accuracy_score"] * 100,
                    domain={"x": [0, 1], "y": [0, 1]},
                    title={"text": "System Accuracy %"},
                    gauge={
                        "axis": {"range": [None, 100]},
                        "bar": {"color": "darkblue"},
                        "steps": [
                            {"range": [0, 50], "color": "lightgray"},
                            {"range": [50, 80], "color": "yellow"},
                            {"range": [80, 100], "color": "green"},
                        ],
                        "threshold": {
                            "line": {"color": "red", "width": 4},
                            "thickness": 0.75,
                            "value": 90,
                        },
                    },
                )
            )
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)

        # Module-Status
        st.subheader("ðŸ”§ Module-Status")
        modules = {
            "Neural Fusion": "ðŸ§  Aktiv",
            "Predictive Completion": "ðŸ”® Aktiv",
            "Auto-Optimization": "ðŸŽ¯ Bereit",
            "Adaptive Learning": "ðŸ“š Lernend",
            "Intelligent Cache": "ðŸ’¾ Aktiv",
        }

        for module, status in modules.items():
            st.write(f"**{module}:** {status}")

        # ZusÃ¤tzliche Analytics
        if "neural_fusion" in analytics:
            st.subheader("ðŸ§  Neural Fusion")
            nf_analytics = analytics["neural_fusion"]
            if "feature_importance" in nf_analytics:
                st.write("**Top-Features:**")
                for feature, importance in list(
                    nf_analytics["feature_importance"].items()
                )[:3]:
                    st.write(f"â€¢ {feature}: {importance:.2%}")
